{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOzzu+3cNAtoaxeIqHxcez4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manjuiitm/mlprojects/blob/main/Credit-card-approval-prediction-classification/cc_approval_pred_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j077TvN06ISR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, OrdinalEncoder\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# from secret import access_key, secret_access_key\n",
        "import joblib\n",
        "import streamlit as st\n",
        "import boto3\n",
        "import tempfile\n",
        "import json\n",
        "import requests\n",
        "from streamlit_lottie import st_lottie_spinner\n",
        "import logging\n",
        "from botocore.exceptions import ClientError\n",
        "\n",
        "\n",
        "train_original = pd.read_csv(\n",
        "    \"https://raw.githubusercontent.com/semasuka/Credit-card-approval-prediction-classification/refs/heads/main/dataset/train.csv\"\n",
        ")\n",
        "\n",
        "test_original = pd.read_csv(\n",
        "    \"https://raw.githubusercontent.com/semasuka/Credit-card-approval-prediction-classification/refs/heads/main/dataset/test.csv\"\n",
        ")\n",
        "\n",
        "full_data = pd.concat([train_original, test_original], axis=0)\n",
        "\n",
        "full_data = full_data.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "\n",
        "def data_split(df, test_size):\n",
        "    train_df, test_df = train_test_split(df, test_size=test_size, random_state=42)\n",
        "    return train_df.reset_index(drop=True), test_df.reset_index(drop=True)\n",
        "\n",
        "\n",
        "train_original, test_original = data_split(full_data, 0.2)\n",
        "\n",
        "train_copy = train_original.copy()\n",
        "test_copy = test_original.copy()\n",
        "\n",
        "\n",
        "def value_cnt_norm_cal(df, feature):\n",
        "    \"\"\"\n",
        "    Function to calculate the count of each value in a feature and normalize it\n",
        "    \"\"\"\n",
        "    ftr_value_cnt = df[feature].value_counts()\n",
        "    ftr_value_cnt_norm = df[feature].value_counts(normalize=True) * 100\n",
        "    ftr_value_cnt_concat = pd.concat([ftr_value_cnt, ftr_value_cnt_norm], axis=1)\n",
        "    ftr_value_cnt_concat.columns = [\"Count\", \"Frequency (%)\"]\n",
        "    return ftr_value_cnt_concat\n",
        "\n",
        "\n",
        "class OutlierRemover(BaseEstimator, TransformerMixin):\n",
        "    def __init__(\n",
        "        self, feat_with_outliers=[\"Family member count\", \"Income\", \"Employment length\"]\n",
        "    ):\n",
        "        self.feat_with_outliers = feat_with_outliers\n",
        "\n",
        "    def fit(self, df):\n",
        "        return self\n",
        "\n",
        "    def transform(self, df):\n",
        "        if set(self.feat_with_outliers).issubset(df.columns):\n",
        "            # 25% quantile\n",
        "            Q1 = df[self.feat_with_outliers].quantile(0.25)\n",
        "            # 75% quantile\n",
        "            Q3 = df[self.feat_with_outliers].quantile(0.75)\n",
        "            IQR = Q3 - Q1\n",
        "            # keep the data within 1.5 IQR\n",
        "            df = df[\n",
        "                ~(\n",
        "                    (df[self.feat_with_outliers] < (Q1 - 3 * IQR))\n",
        "                    | (df[self.feat_with_outliers] > (Q3 + 3 * IQR))\n",
        "                ).any(axis=1)\n",
        "            ]\n",
        "            return df\n",
        "        else:\n",
        "            print(\"One or more features are not in the dataframe\")\n",
        "            return df\n",
        "\n",
        "\n",
        "class DropFeatures(BaseEstimator, TransformerMixin):\n",
        "    def __init__(\n",
        "        self,\n",
        "        feature_to_drop=[\n",
        "            \"Has a mobile phone\",\n",
        "            \"Children count\",\n",
        "            \"Job title\",\n",
        "            \"Account age\",\n",
        "        ],\n",
        "    ):\n",
        "        self.feature_to_drop = feature_to_drop\n",
        "\n",
        "    def fit(self, df):\n",
        "        return self\n",
        "\n",
        "    def transform(self, df):\n",
        "        if set(self.feature_to_drop).issubset(df.columns):\n",
        "            df.drop(self.feature_to_drop, axis=1, inplace=True)\n",
        "            return df\n",
        "        else:\n",
        "            print(\"One or more features are not in the dataframe\")\n",
        "            return df\n",
        "\n",
        "\n",
        "class TimeConversionHandler(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, feat_with_days=[\"Employment length\", \"Age\"]):\n",
        "        self.feat_with_days = feat_with_days\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        if set(self.feat_with_days).issubset(X.columns):\n",
        "            # convert days to absolute value\n",
        "            X[[\"Employment length\", \"Age\"]] = np.abs(X[[\"Employment length\", \"Age\"]])\n",
        "            return X\n",
        "        else:\n",
        "            print(\"One or more features are not in the dataframe\")\n",
        "            return X\n",
        "\n",
        "\n",
        "class RetireeHandler(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def fit(self, df):\n",
        "        return self\n",
        "\n",
        "    def transform(self, df):\n",
        "        if \"Employment length\" in df.columns:\n",
        "            # select rows with employment length is 365243 which corresponds to retirees\n",
        "            df_ret_idx = df[\"Employment length\"][\n",
        "                df[\"Employment length\"] == 365243\n",
        "            ].index\n",
        "            # change 365243 to 0\n",
        "            df.loc[df_ret_idx, \"Employment length\"] = 0\n",
        "            return df\n",
        "        else:\n",
        "            print(\"Employment length is not in the dataframe\")\n",
        "            return df\n",
        "\n",
        "\n",
        "class SkewnessHandler(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, feat_with_skewness=[\"Income\", \"Age\"]):\n",
        "        self.feat_with_skewness = feat_with_skewness\n",
        "\n",
        "    def fit(self, df):\n",
        "        return self\n",
        "\n",
        "    def transform(self, df):\n",
        "        if set(self.feat_with_skewness).issubset(df.columns):\n",
        "            # Handle skewness with cubic root transformation\n",
        "            df[self.feat_with_skewness] = np.cbrt(df[self.feat_with_skewness])\n",
        "            return df\n",
        "        else:\n",
        "            print(\"One or more features are not in the dataframe\")\n",
        "            return df\n",
        "\n",
        "\n",
        "class BinningNumToYN(BaseEstimator, TransformerMixin):\n",
        "    def __init__(\n",
        "        self, feat_with_num_enc=[\"Has a work phone\", \"Has a phone\", \"Has an email\"]\n",
        "    ):\n",
        "        self.feat_with_num_enc = feat_with_num_enc\n",
        "\n",
        "    def fit(self, df):\n",
        "        return self\n",
        "\n",
        "    def transform(self, df):\n",
        "        if set(self.feat_with_num_enc).issubset(df.columns):\n",
        "            # Change 0 to N and 1 to Y for all the features in feat_with_num_enc\n",
        "            for ft in self.feat_with_num_enc:\n",
        "                df[ft] = df[ft].map({1: \"Y\", 0: \"N\"})\n",
        "            return df\n",
        "        else:\n",
        "            print(\"One or more features are not in the dataframe\")\n",
        "            return df\n",
        "\n",
        "\n",
        "class OneHotWithFeatNames(BaseEstimator, TransformerMixin):\n",
        "    def __init__(\n",
        "        self,\n",
        "        one_hot_enc_ft=[\n",
        "            \"Gender\",\n",
        "            \"Marital status\",\n",
        "            \"Dwelling\",\n",
        "            \"Employment status\",\n",
        "            \"Has a car\",\n",
        "            \"Has a property\",\n",
        "            \"Has a work phone\",\n",
        "            \"Has a phone\",\n",
        "            \"Has an email\",\n",
        "        ],\n",
        "    ):\n",
        "        self.one_hot_enc_ft = one_hot_enc_ft\n",
        "\n",
        "    def fit(self, df):\n",
        "        return self\n",
        "\n",
        "    def transform(self, df):\n",
        "        if set(self.one_hot_enc_ft).issubset(df.columns):\n",
        "            # function to one hot encode the features in one_hot_enc_ft\n",
        "            def one_hot_enc(df, one_hot_enc_ft):\n",
        "                one_hot_enc = OneHotEncoder()\n",
        "                one_hot_enc.fit(df[one_hot_enc_ft])\n",
        "                # get the result of the one hot encoding columns names\n",
        "                feat_names_one_hot_enc = one_hot_enc.get_feature_names_out(\n",
        "                    one_hot_enc_ft\n",
        "                )\n",
        "                # change the array of the one hot encoding to a dataframe with the column names\n",
        "                df = pd.DataFrame(\n",
        "                    one_hot_enc.transform(df[self.one_hot_enc_ft]).toarray(),\n",
        "                    columns=feat_names_one_hot_enc,\n",
        "                    index=df.index,\n",
        "                )\n",
        "                return df\n",
        "\n",
        "            # function to concatenat the one hot encoded features with the rest of features that were not encoded\n",
        "            def concat_with_rest(df, one_hot_enc_df, one_hot_enc_ft):\n",
        "                # get the rest of the features\n",
        "                rest_of_features = [ft for ft in df.columns if ft not in one_hot_enc_ft]\n",
        "                # concatenate the rest of the features with the one hot encoded features\n",
        "                df_concat = pd.concat([one_hot_enc_df, df[rest_of_features]], axis=1)\n",
        "                return df_concat\n",
        "\n",
        "            # one hot encoded dataframe\n",
        "            one_hot_enc_df = one_hot_enc(df, self.one_hot_enc_ft)\n",
        "            # returns the concatenated dataframe\n",
        "            full_df_one_hot_enc = concat_with_rest(\n",
        "                df, one_hot_enc_df, self.one_hot_enc_ft\n",
        "            )\n",
        "            print(full_df_one_hot_enc.tail(25))\n",
        "            return full_df_one_hot_enc\n",
        "        else:\n",
        "            print(\"One or more features are not in the dataframe\")\n",
        "            return df\n",
        "\n",
        "\n",
        "class OrdinalFeatNames(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, ordinal_enc_ft=[\"Education level\"]):\n",
        "        self.ordinal_enc_ft = ordinal_enc_ft\n",
        "\n",
        "    def fit(self, df):\n",
        "        return self\n",
        "\n",
        "    def transform(self, df):\n",
        "        if \"Education level\" in df.columns:\n",
        "            ordinal_enc = OrdinalEncoder()\n",
        "            df[self.ordinal_enc_ft] = ordinal_enc.fit_transform(df[self.ordinal_enc_ft])\n",
        "            return df\n",
        "        else:\n",
        "            print(\"Education level is not in the dataframe\")\n",
        "            return df\n",
        "\n",
        "\n",
        "class MinMaxWithFeatNames(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, min_max_scaler_ft=[\"Age\", \"Income\", \"Employment length\"]):\n",
        "        self.min_max_scaler_ft = min_max_scaler_ft\n",
        "\n",
        "    def fit(self, df):\n",
        "        return self\n",
        "\n",
        "    def transform(self, df):\n",
        "        if set(self.min_max_scaler_ft).issubset(df.columns):\n",
        "            min_max_enc = MinMaxScaler()\n",
        "            df[self.min_max_scaler_ft] = min_max_enc.fit_transform(\n",
        "                df[self.min_max_scaler_ft]\n",
        "            )\n",
        "            return df\n",
        "        else:\n",
        "            print(\"One or more features are not in the dataframe\")\n",
        "            return df\n",
        "\n",
        "\n",
        "class ChangeToNumTarget(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def fit(self, df):\n",
        "        return self\n",
        "\n",
        "    def transform(self, df):\n",
        "        if \"Is high risk\" in df.columns:\n",
        "            df[\"Is high risk\"] = pd.to_numeric(df[\"Is high risk\"])\n",
        "            return df\n",
        "        else:\n",
        "            print(\"Is high risk is not in the dataframe\")\n",
        "            return df\n",
        "\n",
        "\n",
        "class OversampleSMOTE(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def fit(self, df):\n",
        "        return self\n",
        "\n",
        "    def transform(self, df):\n",
        "        if \"Is high risk\" in df.columns:\n",
        "            # SMOTE function to oversample the minority class to fix the imbalance data\n",
        "            smote = SMOTE()\n",
        "            X_bal, y_bal = smote.fit_resample(df.iloc[:, :-1], df.iloc[:, -1])\n",
        "            X_y_bal = pd.concat([pd.DataFrame(X_bal), pd.DataFrame(y_bal)], axis=1)\n",
        "            return X_y_bal\n",
        "        else:\n",
        "            print(\"Is high risk is not in the dataframe\")\n",
        "            return df\n",
        "\n",
        "\n",
        "def full_pipeline(df):\n",
        "    # Create the pipeline that will call all the class from OutlierRemoval to OversampleSMOTE in one go\n",
        "    pipeline = Pipeline(\n",
        "        [\n",
        "            (\"outlier_remover\", OutlierRemover()),\n",
        "            (\"feature_dropper\", DropFeatures()),\n",
        "            (\"time_conversion_handler\", TimeConversionHandler()),\n",
        "            (\"retiree_handler\", RetireeHandler()),\n",
        "            (\"skewness_handler\", SkewnessHandler()),\n",
        "            (\"binning_num_to_yn\", BinningNumToYN()),\n",
        "            (\"one_hot_with_feat_names\", OneHotWithFeatNames()),\n",
        "            (\"ordinal_feat_names\", OrdinalFeatNames()),\n",
        "            (\"min_max_with_feat_names\", MinMaxWithFeatNames()),\n",
        "            (\"change_to_num_target\", ChangeToNumTarget()),\n",
        "            (\"oversample_smote\", OversampleSMOTE()),\n",
        "        ]\n",
        "    )\n",
        "    df_pipe_prep = pipeline.fit_transform(df)\n",
        "    return df_pipe_prep\n",
        "\n",
        "\n",
        "############################# Streamlit ############################\n",
        "\n",
        "st.write(\"\"\"\n",
        "# Credit card approval prediction\n",
        "This app predicts if an applicant will be approved for a credit card or not. Just fill in the following information and click on the Predict button.\n",
        "\"\"\")\n",
        "\n",
        "# Gender input\n",
        "st.write(\"\"\"\n",
        "## Gender\n",
        "\"\"\")\n",
        "input_gender = st.radio(\"Select you gender\", [\"Male\", \"Female\"], index=0)\n",
        "\n",
        "\n",
        "# Age input slider\n",
        "st.write(\"\"\"\n",
        "## Age\n",
        "\"\"\")\n",
        "input_age = np.negative(\n",
        "    st.slider(\"Select your age\", value=42, min_value=18, max_value=70, step=1) * 365.25\n",
        ")\n",
        "\n",
        "\n",
        "# Marital status input dropdown\n",
        "st.write(\"\"\"\n",
        "## Marital status\n",
        "\"\"\")\n",
        "marital_status_values = list(value_cnt_norm_cal(full_data, \"Marital status\").index)\n",
        "marital_status_key = [\n",
        "    \"Married\",\n",
        "    \"Single/not married\",\n",
        "    \"Civil marriage\",\n",
        "    \"Separated\",\n",
        "    \"Widowed\",\n",
        "]\n",
        "marital_status_dict = dict(zip(marital_status_key, marital_status_values))\n",
        "input_marital_status_key = st.selectbox(\n",
        "    \"Select your marital status\", marital_status_key\n",
        ")\n",
        "input_marital_status_val = marital_status_dict.get(input_marital_status_key)\n",
        "\n",
        "\n",
        "# Family member count\n",
        "st.write(\"\"\"\n",
        "## Family member count\n",
        "\"\"\")\n",
        "fam_member_count = float(\n",
        "    st.selectbox(\"Select your family member count\", [1, 2, 3, 4, 5, 6])\n",
        ")\n",
        "\n",
        "\n",
        "# Dwelling type dropdown\n",
        "st.write(\"\"\"\n",
        "## Dwelling type\n",
        "\"\"\")\n",
        "dwelling_type_values = list(value_cnt_norm_cal(full_data, \"Dwelling\").index)\n",
        "dwelling_type_key = [\n",
        "    \"House / apartment\",\n",
        "    \"Live with parents\",\n",
        "    \"Municipal apartment \",\n",
        "    \"Rented apartment\",\n",
        "    \"Office apartment\",\n",
        "    \"Co-op apartment\",\n",
        "]\n",
        "dwelling_type_dict = dict(zip(dwelling_type_key, dwelling_type_values))\n",
        "input_dwelling_type_key = st.selectbox(\n",
        "    \"Select the type of dwelling you reside in\", dwelling_type_key\n",
        ")\n",
        "input_dwelling_type_val = dwelling_type_dict.get(input_dwelling_type_key)\n",
        "\n",
        "\n",
        "# Income\n",
        "st.write(\"\"\"\n",
        "## Income\n",
        "\"\"\")\n",
        "input_income = int(st.text_input(\"Enter your income (in USD)\", 0))\n",
        "\n",
        "# Employment status dropdown\n",
        "st.write(\"\"\"\n",
        "## Employment status\n",
        "\"\"\")\n",
        "employment_status_values = list(\n",
        "    value_cnt_norm_cal(full_data, \"Employment status\").index\n",
        ")\n",
        "employment_status_key = [\n",
        "    \"Working\",\n",
        "    \"Commercial associate\",\n",
        "    \"Pensioner\",\n",
        "    \"State servant\",\n",
        "    \"Student\",\n",
        "]\n",
        "employment_status_dict = dict(zip(employment_status_key, employment_status_values))\n",
        "input_employment_status_key = st.selectbox(\n",
        "    \"Select your employment status\", employment_status_key\n",
        ")\n",
        "input_employment_status_val = employment_status_dict.get(input_employment_status_key)\n",
        "\n",
        "\n",
        "# Employment length input slider\n",
        "st.write(\"\"\"\n",
        "## Employment length\n",
        "\"\"\")\n",
        "input_employment_length = np.negative(\n",
        "    st.slider(\n",
        "        \"Select your employment length\", value=6, min_value=0, max_value=30, step=1\n",
        "    )\n",
        "    * 365.25\n",
        ")\n",
        "\n",
        "\n",
        "# Education level dropdown\n",
        "st.write(\"\"\"\n",
        "## Education level\n",
        "\"\"\")\n",
        "edu_level_values = list(value_cnt_norm_cal(full_data, \"Education level\").index)\n",
        "edu_level_key = [\n",
        "    \"Secondary school\",\n",
        "    \"Higher education\",\n",
        "    \"Incomplete higher\",\n",
        "    \"Lower secondary\",\n",
        "    \"Academic degree\",\n",
        "]\n",
        "edu_level_dict = dict(zip(edu_level_key, edu_level_values))\n",
        "input_edu_level_key = st.selectbox(\"Select your education status\", edu_level_key)\n",
        "input_edu_level_val = edu_level_dict.get(input_edu_level_key)\n",
        "\n",
        "\n",
        "# Car ownship input\n",
        "st.write(\"\"\"\n",
        "## Car ownship\n",
        "\"\"\")\n",
        "input_car_ownship = st.radio(\"Do you own a car?\", [\"Yes\", \"No\"], index=0)\n",
        "\n",
        "# Property ownship input\n",
        "st.write(\"\"\"\n",
        "## Property ownship\n",
        "\"\"\")\n",
        "input_prop_ownship = st.radio(\"Do you own a property?\", [\"Yes\", \"No\"], index=0)\n",
        "\n",
        "\n",
        "# Work phone input\n",
        "st.write(\"\"\"\n",
        "## Work phone\n",
        "\"\"\")\n",
        "input_work_phone = st.radio(\"Do you have a work phone?\", [\"Yes\", \"No\"], index=0)\n",
        "work_phone_dict = {\"Yes\": 1, \"No\": 0}\n",
        "work_phone_val = work_phone_dict.get(input_work_phone)\n",
        "\n",
        "# Phone input\n",
        "st.write(\"\"\"\n",
        "## Phone\n",
        "\"\"\")\n",
        "input_phone = st.radio(\"Do you have a phone?\", [\"Yes\", \"No\"], index=0)\n",
        "work_dict = {\"Yes\": 1, \"No\": 0}\n",
        "phone_val = work_dict.get(input_phone)\n",
        "\n",
        "# Email input\n",
        "st.write(\"\"\"\n",
        "## Email\n",
        "\"\"\")\n",
        "input_email = st.radio(\"Do you have an email?\", [\"Yes\", \"No\"], index=0)\n",
        "email_dict = {\"Yes\": 1, \"No\": 0}\n",
        "email_val = email_dict.get(input_email)\n",
        "\n",
        "st.markdown(\"##\")\n",
        "st.markdown(\"##\")\n",
        "# Button\n",
        "predict_bt = st.button(\"Predict\")\n",
        "\n",
        "# list of all the input variables\n",
        "profile_to_predict = [\n",
        "    0,  # ID\n",
        "    input_gender[:1],  # gender\n",
        "    input_car_ownship[:1],  # car ownership\n",
        "    input_prop_ownship[:1],  # property ownership\n",
        "    0,  # Children count (which will be dropped in the pipeline)\n",
        "    input_income,  # Income\n",
        "    input_employment_status_val,  # Employment status\n",
        "    input_edu_level_val,  # Education level\n",
        "    input_marital_status_val,  # Marital status\n",
        "    input_dwelling_type_val,  # Dwelling type\n",
        "    input_age,  # Age\n",
        "    input_employment_length,  # Employment length\n",
        "    1,  # Has a mobile phone (which will be dropped in the pipeline)\n",
        "    work_phone_val,  # Work phone\n",
        "    phone_val,  # Phone\n",
        "    email_val,  # Email\n",
        "    \"to_be_droped\",  # Job title (which will be dropped in the pipeline)\n",
        "    fam_member_count,  # Family member count\n",
        "    0.00,  # Account age (which will be dropped in the pipeline)\n",
        "    0,  # target set to 0 as a placeholder\n",
        "]\n",
        "\n",
        "\n",
        "profile_to_predict_df = pd.DataFrame([profile_to_predict], columns=train_copy.columns)\n",
        "\n",
        "\n",
        "# add the profile to predict as a last row in the train data\n",
        "train_copy_with_profile_to_pred = pd.concat(\n",
        "    [train_copy, profile_to_predict_df], ignore_index=True\n",
        ")\n",
        "\n",
        "\n",
        "# whole dataset prepared\n",
        "train_copy_with_profile_to_pred_prep = full_pipeline(train_copy_with_profile_to_pred)\n",
        "\n",
        "# Get the row with the ID = 0, and drop the ID, and target(placeholder) column\n",
        "profile_to_pred_prep = train_copy_with_profile_to_pred_prep[\n",
        "    train_copy_with_profile_to_pred_prep[\"ID\"] == 0\n",
        "].drop(columns=[\"ID\", \"Is high risk\"])\n",
        "\n",
        "\n",
        "# Animation function\n",
        "@st.cache_data\n",
        "def load_lottieurl(url: str):\n",
        "    r = requests.get(url)\n",
        "    if r.status_code != 200:\n",
        "        return None\n",
        "    return r.json()\n",
        "\n",
        "\n",
        "lottie_loading_an = load_lottieurl(\n",
        "    \"https://assets3.lottiefiles.com/packages/lf20_szlepvdh.json\"\n",
        ")\n",
        "\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "def make_prediction():\n",
        "    bucket_name = \"creditapplipred\"\n",
        "    key = \"gradient_boosting_model.sav\"\n",
        "\n",
        "    client = boto3.client(\n",
        "        \"s3\",\n",
        "        aws_access_key_id=st.secrets[\"access_key\"],\n",
        "        aws_secret_access_key=st.secrets[\"secret_access_key\"],\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        # Test S3 access\n",
        "        logger.info(f\"Attempting to list objects in {bucket_name}\")\n",
        "        response = client.list_objects_v2(Bucket=bucket_name, MaxKeys=1)\n",
        "        logger.info(\"Successfully listed bucket contents\")\n",
        "\n",
        "        logger.info(f\"Attempting to download {key} from {bucket_name}\")\n",
        "        with tempfile.TemporaryFile() as fp:\n",
        "            client.download_fileobj(Fileobj=fp, Bucket=bucket_name, Key=key)\n",
        "            logger.info(\"Successfully downloaded the file\")\n",
        "            fp.seek(0)\n",
        "            model = joblib.load(fp)\n",
        "            logger.info(\"Successfully loaded the model\")\n",
        "\n",
        "        return model.predict(profile_to_pred_prep)\n",
        "    except ClientError as e:\n",
        "        error_code = e.response[\"Error\"][\"Code\"]\n",
        "        error_message = e.response[\"Error\"][\"Message\"]\n",
        "        logger.error(f\"ClientError: {error_code} - {error_message}\")\n",
        "        st.error(f\"AWS Error: {error_code} - {error_message}\")\n",
        "        if error_code == \"AccessDenied\":\n",
        "            st.error(\"Access Denied. Please check your AWS permissions.\")\n",
        "        elif error_code == \"NoSuchBucket\":\n",
        "            st.error(f\"The bucket {bucket_name} does not exist.\")\n",
        "        elif error_code == \"NoSuchKey\":\n",
        "            st.error(f\"The key {key} does not exist in the bucket.\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Unexpected error: {str(e)}\")\n",
        "        st.error(f\"An unexpected error occurred: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "if predict_bt:\n",
        "    with st_lottie_spinner(\n",
        "        lottie_loading_an, quality=\"high\", height=\"200px\", width=\"200px\"\n",
        "    ):\n",
        "        final_pred = make_prediction()\n",
        "    if final_pred is not None:\n",
        "        if final_pred[0] == 0:\n",
        "            st.success(\"## You have been approved for a credit card\")\n",
        "            st.balloons()\n",
        "        elif final_pred[0] == 1:\n",
        "            st.error(\"## Unfortunately, you have not been approved for a credit card\")\n",
        "    else:\n",
        "        st.error(\n",
        "            \"Unable to make a prediction due to an error. Please check the logs and try again.\"\n",
        "        )"
      ]
    }
  ]
}